{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e379bc2",
   "metadata": {},
   "source": [
    "## ðŸ“¦ 1. Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26379016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    hamming_loss, accuracy_score, classification_report\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Seed pour reproductibilitÃ©\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "print(\"\\nâœ… Imports rÃ©ussis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2f19ad",
   "metadata": {},
   "source": [
    "## ðŸ“‚ 2. Chargement des DonnÃ©es PrÃ©parÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031011bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chargement des donnÃ©es...\\n\")\n",
    "\n",
    "# Charger les sÃ©quences\n",
    "X_train = np.load('data/processed/X_train.npy')\n",
    "X_val = np.load('data/processed/X_val.npy')\n",
    "X_test = np.load('data/processed/X_test.npy')\n",
    "print(\"âœ… SÃ©quences chargÃ©es\")\n",
    "\n",
    "# Charger les labels\n",
    "y_train = np.load('data/processed/y_train.npy')\n",
    "y_val = np.load('data/processed/y_val.npy')\n",
    "y_test = np.load('data/processed/y_test.npy')\n",
    "print(\"âœ… Labels chargÃ©s\")\n",
    "\n",
    "# Charger les mÃ©tadonnÃ©es\n",
    "with open('data/processed/metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "print(\"âœ… MÃ©tadonnÃ©es chargÃ©es\")\n",
    "\n",
    "# Extraire les paramÃ¨tres\n",
    "emotion_labels = metadata['emotion_labels']\n",
    "NUM_CLASSES = metadata['num_classes']\n",
    "MAX_VOCAB_SIZE = metadata['max_vocab_size']\n",
    "MAX_SEQUENCE_LENGTH = metadata['max_sequence_length']\n",
    "\n",
    "print(f\"\\nðŸ“Š Configuration:\")\n",
    "print(f\"  Train samples: {len(X_train):,}\")\n",
    "print(f\"  Val samples:   {len(X_val):,}\")\n",
    "print(f\"  Test samples:  {len(X_test):,}\")\n",
    "print(f\"  Num classes:   {NUM_CLASSES}\")\n",
    "print(f\"  Vocab size:    {MAX_VOCAB_SIZE:,}\")\n",
    "print(f\"  Seq length:    {MAX_SEQUENCE_LENGTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd86df",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ 3. Construction du ModÃ¨le LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3199bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(vocab_size, embedding_dim=128, lstm_units=64, \n",
    "                     num_classes=28, max_length=128, dropout_rate=0.5):\n",
    "    \"\"\"\n",
    "    Construire un modÃ¨le LSTM simple pour classification multi-label\n",
    "    \n",
    "    Args:\n",
    "        vocab_size: Taille du vocabulaire\n",
    "        embedding_dim: Dimension des embeddings\n",
    "        lstm_units: Nombre d'unitÃ©s LSTM\n",
    "        num_classes: Nombre de classes (Ã©motions)\n",
    "        max_length: Longueur maximale des sÃ©quences\n",
    "        dropout_rate: Taux de dropout\n",
    "    \n",
    "    Returns:\n",
    "        ModÃ¨le Keras compilÃ©\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # Embedding layer\n",
    "        layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            input_length=max_length,\n",
    "            mask_zero=True,\n",
    "            name='embedding'\n",
    "        ),\n",
    "        \n",
    "        # LSTM layer\n",
    "        layers.LSTM(lstm_units, name='lstm'),\n",
    "        \n",
    "        # Dropout pour rÃ©gularisation\n",
    "        layers.Dropout(dropout_rate, name='dropout'),\n",
    "        \n",
    "        # Output layer (sigmoid pour multi-label)\n",
    "        layers.Dense(num_classes, activation='sigmoid', name='output')\n",
    "    ], name='SimpleLSTM')\n",
    "    \n",
    "    # Compiler le modÃ¨le\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            keras.metrics.Precision(name='precision'),\n",
    "            keras.metrics.Recall(name='recall')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Construire le modÃ¨le\n",
    "print(\"Construction du modÃ¨le LSTM...\\n\")\n",
    "lstm_model = build_lstm_model(\n",
    "    vocab_size=MAX_VOCAB_SIZE,\n",
    "    embedding_dim=128,\n",
    "    lstm_units=64,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    max_length=MAX_SEQUENCE_LENGTH,\n",
    "    dropout_rate=0.5\n",
    ")\n",
    "\n",
    "# Afficher l'architecture\n",
    "lstm_model.summary()\n",
    "\n",
    "print(f\"\\nâœ… ModÃ¨le LSTM construit!\")\n",
    "print(f\"  ParamÃ¨tres totaux: {lstm_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15d9c1",
   "metadata": {},
   "source": [
    "## ðŸŽ“ 4. EntraÃ®nement du ModÃ¨le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ca015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'models/lstm/best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸš€ DÃ‰BUT DE L'ENTRAÃŽNEMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(f\"Heure de dÃ©but: {start_time.strftime('%H:%M:%S')}\\n\")\n",
    "\n",
    "# EntraÃ®nement\n",
    "history = lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "training_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… ENTRAÃŽNEMENT TERMINÃ‰\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Temps d'entraÃ®nement: {training_time/60:.2f} minutes\")\n",
    "print(f\"Heure de fin: {end_time.strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0821f695",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ 5. Visualisation de l'EntraÃ®nement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d83c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbes d'entraÃ®nement\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "axes[0, 0].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Loss', fontweight='bold')\n",
    "axes[0, 0].set_title('Loss pendant l\\'entraÃ®nement', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "axes[0, 1].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Accuracy', fontweight='bold')\n",
    "axes[0, 1].set_title('Accuracy pendant l\\'entraÃ®nement', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].plot(history.history['precision'], label='Train', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Validation', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Precision', fontweight='bold')\n",
    "axes[1, 0].set_title('Precision pendant l\\'entraÃ®nement', fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].plot(history.history['recall'], label='Train', linewidth=2)\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Validation', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Recall', fontweight='bold')\n",
    "axes[1, 1].set_title('Recall pendant l\\'entraÃ®nement', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/lstm_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Graphiques sauvegardÃ©s!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5427ed4b",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ 6. Ã‰valuation sur le Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20892d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Š Ã‰VALUATION SUR LE TEST SET\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# PrÃ©dictions\n",
    "print(\"GÃ©nÃ©ration des prÃ©dictions...\")\n",
    "y_pred_proba = lstm_model.predict(X_test, verbose=0)\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "print(\"âœ… PrÃ©dictions gÃ©nÃ©rÃ©es\\n\")\n",
    "\n",
    "# Calculer les mÃ©triques\n",
    "results = {\n",
    "    'model_name': 'LSTM',\n",
    "    'precision_micro': precision_score(y_test, y_pred, average='micro', zero_division=0),\n",
    "    'precision_macro': precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "    'recall_micro': recall_score(y_test, y_pred, average='micro', zero_division=0),\n",
    "    'recall_macro': recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "    'f1_micro': f1_score(y_test, y_pred, average='micro', zero_division=0),\n",
    "    'f1_macro': f1_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "    'hamming_loss': hamming_loss(y_test, y_pred),\n",
    "    'subset_accuracy': accuracy_score(y_test, y_pred),\n",
    "    'training_time_minutes': training_time / 60,\n",
    "    'num_parameters': lstm_model.count_params()\n",
    "}\n",
    "\n",
    "# Afficher les rÃ©sultats\n",
    "print(\"ðŸ“ˆ RÃ‰SULTATS:\")\n",
    "print(\"-\" * 60)\n",
    "for metric, value in results.items():\n",
    "    if metric not in ['model_name', 'training_time_minutes', 'num_parameters']:\n",
    "        print(f\"{metric:25s}: {value:.4f}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Temps d'entraÃ®nement: {results['training_time_minutes']:.2f} minutes\")\n",
    "print(f\"ParamÃ¨tres du modÃ¨le: {results['num_parameters']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ec3a0",
   "metadata": {},
   "source": [
    "## ðŸ“Š 7. Analyse DÃ©taillÃ©e par Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24576a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des mÃ©triques par classe\n",
    "precision_per_class = precision_score(y_test, y_pred, average=None, zero_division=0)\n",
    "recall_per_class = recall_score(y_test, y_pred, average=None, zero_division=0)\n",
    "f1_per_class = f1_score(y_test, y_pred, average=None, zero_division=0)\n",
    "\n",
    "# CrÃ©er un DataFrame\n",
    "per_class_df = pd.DataFrame({\n",
    "    'Emotion': emotion_labels,\n",
    "    'Precision': precision_per_class,\n",
    "    'Recall': recall_per_class,\n",
    "    'F1-Score': f1_per_class\n",
    "})\n",
    "\n",
    "# Trier par F1-Score\n",
    "per_class_df = per_class_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š MÃ©triques par Ã©motion (Top 10):\")\n",
    "print(per_class_df.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nðŸ“Š MÃ©triques par Ã©motion (Bottom 5):\")\n",
    "print(per_class_df.tail(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017eac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des mÃ©triques par classe\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "x = np.arange(len(emotion_labels))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, precision_per_class, width, label='Precision', alpha=0.8)\n",
    "ax.bar(x, recall_per_class, width, label='Recall', alpha=0.8)\n",
    "ax.bar(x + width, f1_per_class, width, label='F1-Score', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Ã‰motion', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
    "ax.set_title('MÃ©triques par Ã‰motion - ModÃ¨le LSTM', fontweight='bold', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(emotion_labels, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/lstm_per_class_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f28a666",
   "metadata": {},
   "source": [
    "## ðŸ’¾ 8. Sauvegarde des RÃ©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f14b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sauvegarde des rÃ©sultats...\\n\")\n",
    "\n",
    "# Sauvegarder le modÃ¨le final\n",
    "lstm_model.save('models/lstm/final_model.h5')\n",
    "print(\"âœ… ModÃ¨le sauvegardÃ©: models/lstm/final_model.h5\")\n",
    "\n",
    "# Sauvegarder l'historique d'entraÃ®nement\n",
    "with open('models/lstm/training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "print(\"âœ… Historique sauvegardÃ©: models/lstm/training_history.pkl\")\n",
    "\n",
    "# Sauvegarder les rÃ©sultats au format JSON\n",
    "with open('results/metrics/lstm_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "print(\"âœ… RÃ©sultats sauvegardÃ©s: results/metrics/lstm_results.json\")\n",
    "\n",
    "# Sauvegarder les prÃ©dictions\n",
    "np.save('models/lstm/test_predictions.npy', y_pred)\n",
    "np.save('models/lstm/test_probabilities.npy', y_pred_proba)\n",
    "print(\"âœ… PrÃ©dictions sauvegardÃ©es\")\n",
    "\n",
    "# Sauvegarder les mÃ©triques par classe\n",
    "per_class_df.to_csv('results/metrics/lstm_per_class_metrics.csv', index=False)\n",
    "print(\"âœ… MÃ©triques par classe sauvegardÃ©es: results/metrics/lstm_per_class_metrics.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ‰ LSTM - ENTRAÃŽNEMENT ET Ã‰VALUATION TERMINÃ‰S !\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nProcÃ©dez au notebook suivant:\")\n",
    "print(\"  ðŸ““ Notebook_2_BiLSTM_Attention.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ff653",
   "metadata": {},
   "source": [
    "## ðŸ“¤ 9. [Optionnel] Sauvegarder vers Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monter Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copier les rÃ©sultats\n",
    "!mkdir -p \"/content/drive/MyDrive/emotion_detection_project\"\n",
    "!cp -r models/lstm \"/content/drive/MyDrive/emotion_detection_project/\"\n",
    "!cp -r results \"/content/drive/MyDrive/emotion_detection_project/\"\n",
    "\n",
    "print(\"\\nâœ… RÃ©sultats LSTM sauvegardÃ©s dans Google Drive!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
