{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e379bc2",
   "metadata": {},
   "source": [
    "## ðŸ“¦ 1. Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26379016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    hamming_loss, accuracy_score, classification_report,\n",
    "    roc_auc_score, roc_curve, auc\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Seed pour reproductibilitÃ©\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "print(\"\\nâœ… Imports rÃ©ussis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2f19ad",
   "metadata": {},
   "source": [
    "## ðŸ“‚ 2. Chargement des DonnÃ©es PrÃ©parÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031011bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monter Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"Chargement des donnÃ©es depuis Google Drive...\\n\")\n",
    "\n",
    "# DÃ©finir le chemin vers les donnÃ©es dans Drive\n",
    "DATA_PATH = '/content/drive/MyDrive/emotion_detection_project/processed'\n",
    "\n",
    "# Charger les sÃ©quences\n",
    "X_train = np.load(f'{DATA_PATH}/X_train.npy')\n",
    "X_val = np.load(f'{DATA_PATH}/X_val.npy')\n",
    "X_test = np.load(f'{DATA_PATH}/X_test.npy')\n",
    "print(\"âœ… SÃ©quences chargÃ©es\")\n",
    "\n",
    "# Charger les labels\n",
    "y_train = np.load(f'{DATA_PATH}/y_train.npy')\n",
    "y_val = np.load(f'{DATA_PATH}/y_val.npy')\n",
    "y_test = np.load(f'{DATA_PATH}/y_test.npy')\n",
    "print(\"âœ… Labels chargÃ©s\")\n",
    "\n",
    "# Charger les mÃ©tadonnÃ©es\n",
    "with open(f'{DATA_PATH}/metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "print(\"âœ… MÃ©tadonnÃ©es chargÃ©es\")\n",
    "\n",
    "# Extraire les paramÃ¨tres\n",
    "emotion_labels = metadata['emotion_labels']\n",
    "NUM_CLASSES = metadata['num_classes']\n",
    "MAX_VOCAB_SIZE = metadata['max_vocab_size']\n",
    "MAX_SEQUENCE_LENGTH = metadata['max_sequence_length']\n",
    "\n",
    "print(f\"\\nðŸ“Š Configuration:\")\n",
    "print(f\"  Train samples: {len(X_train):,}\")\n",
    "print(f\"  Val samples:   {len(X_val):,}\")\n",
    "print(f\"  Test samples:  {len(X_test):,}\")\n",
    "print(f\"  Num classes:   {NUM_CLASSES}\")\n",
    "print(f\"  Vocab size:    {MAX_VOCAB_SIZE:,}\")\n",
    "print(f\"  Seq length:    {MAX_SEQUENCE_LENGTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd86df",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ 3. Construction du ModÃ¨le LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3199bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(vocab_size, embedding_dim=128, lstm_units=64, \n",
    "                     num_classes=28, max_length=128, dropout_rate=0.5):\n",
    "    \"\"\"\n",
    "    Construire un modÃ¨le LSTM simple pour classification multi-label\n",
    "    \n",
    "    Args:\n",
    "        vocab_size: Taille du vocabulaire\n",
    "        embedding_dim: Dimension des embeddings\n",
    "        lstm_units: Nombre d'unitÃ©s LSTM\n",
    "        num_classes: Nombre de classes (Ã©motions)\n",
    "        max_length: Longueur maximale des sÃ©quences\n",
    "        dropout_rate: Taux de dropout\n",
    "    \n",
    "    Returns:\n",
    "        ModÃ¨le Keras compilÃ©\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # Embedding layer\n",
    "        layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            input_length=max_length,\n",
    "            mask_zero=True,\n",
    "            name='embedding'\n",
    "        ),\n",
    "        \n",
    "        # LSTM layer\n",
    "        layers.LSTM(lstm_units, name='lstm'),\n",
    "        \n",
    "        # Dropout pour rÃ©gularisation\n",
    "        layers.Dropout(dropout_rate, name='dropout'),\n",
    "        \n",
    "        # Output layer (sigmoid pour multi-label)\n",
    "        layers.Dense(num_classes, activation='sigmoid', name='output')\n",
    "    ], name='SimpleLSTM')\n",
    "    \n",
    "    # Compiler le modÃ¨le\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            keras.metrics.Precision(name='precision'),\n",
    "            keras.metrics.Recall(name='recall')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Construire le modÃ¨le\n",
    "print(\"Construction du modÃ¨le LSTM...\\n\")\n",
    "lstm_model = build_lstm_model(\n",
    "    vocab_size=MAX_VOCAB_SIZE,\n",
    "    embedding_dim=128,\n",
    "    lstm_units=64,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    max_length=MAX_SEQUENCE_LENGTH,\n",
    "    dropout_rate=0.5\n",
    ")\n",
    "\n",
    "# Afficher l'architecture\n",
    "lstm_model.summary()\n",
    "\n",
    "print(f\"\\nâœ… ModÃ¨le LSTM construit!\")\n",
    "print(f\"  ParamÃ¨tres totaux: {lstm_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15d9c1",
   "metadata": {},
   "source": [
    "## ðŸŽ“ 4. EntraÃ®nement du ModÃ¨le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ca015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'models/lstm/best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸš€ DÃ‰BUT DE L'ENTRAÃŽNEMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(f\"Heure de dÃ©but: {start_time.strftime('%H:%M:%S')}\\n\")\n",
    "\n",
    "# EntraÃ®nement\n",
    "history = lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "training_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… ENTRAÃŽNEMENT TERMINÃ‰\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Temps d'entraÃ®nement: {training_time/60:.2f} minutes\")\n",
    "print(f\"Heure de fin: {end_time.strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0821f695",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ 5. Visualisation de l'EntraÃ®nement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d83c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbes d'entraÃ®nement\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "axes[0, 0].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Loss', fontweight='bold')\n",
    "axes[0, 0].set_title('Loss pendant l\\'entraÃ®nement', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "axes[0, 1].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Accuracy', fontweight='bold')\n",
    "axes[0, 1].set_title('Accuracy pendant l\\'entraÃ®nement', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].plot(history.history['precision'], label='Train', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Validation', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Precision', fontweight='bold')\n",
    "axes[1, 0].set_title('Precision pendant l\\'entraÃ®nement', fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].plot(history.history['recall'], label='Train', linewidth=2)\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Validation', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Recall', fontweight='bold')\n",
    "axes[1, 1].set_title('Recall pendant l\\'entraÃ®nement', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/lstm_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Graphiques sauvegardÃ©s!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5427ed4b",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ 6. Ã‰valuation sur le Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20892d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Š Ã‰VALUATION SUR LE TEST SET\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# PrÃ©dictions\n",
    "print(\"GÃ©nÃ©ration des prÃ©dictions...\")\n",
    "y_pred_proba = lstm_model.predict(X_test, verbose=0)\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "print(\"âœ… PrÃ©dictions gÃ©nÃ©rÃ©es\\n\")\n",
    "\n",
    "# Calculer les mÃ©triques\n",
    "results = {\n",
    "    'model_name': 'LSTM',\n",
    "    'precision_micro': precision_score(y_test, y_pred, average='micro', zero_division=0),\n",
    "    'precision_macro': precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "    'recall_micro': recall_score(y_test, y_pred, average='micro', zero_division=0),\n",
    "    'recall_macro': recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "    'f1_micro': f1_score(y_test, y_pred, average='micro', zero_division=0),\n",
    "    'f1_macro': f1_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "    'hamming_loss': hamming_loss(y_test, y_pred),\n",
    "    'subset_accuracy': accuracy_score(y_test, y_pred),\n",
    "    'training_time_minutes': training_time / 60,\n",
    "    'num_parameters': lstm_model.count_params()\n",
    "}\n",
    "\n",
    "# Afficher les rÃ©sultats\n",
    "print(\"ðŸ“ˆ RÃ‰SULTATS:\")\n",
    "print(\"-\" * 60)\n",
    "for metric, value in results.items():\n",
    "    if metric not in ['model_name', 'training_time_minutes', 'num_parameters']:\n",
    "        print(f\"{metric:25s}: {value:.4f}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Temps d'entraÃ®nement: {results['training_time_minutes']:.2f} minutes\")\n",
    "print(f\"ParamÃ¨tres du modÃ¨le: {results['num_parameters']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ec3a0",
   "metadata": {},
   "source": [
    "## ðŸ“Š 7. Analyse DÃ©taillÃ©e par Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24576a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des mÃ©triques par classe\n",
    "precision_per_class = precision_score(y_test, y_pred, average=None, zero_division=0)\n",
    "recall_per_class = recall_score(y_test, y_pred, average=None, zero_division=0)\n",
    "f1_per_class = f1_score(y_test, y_pred, average=None, zero_division=0)\n",
    "\n",
    "# CrÃ©er un DataFrame\n",
    "per_class_df = pd.DataFrame({\n",
    "    'Emotion': emotion_labels,\n",
    "    'Precision': precision_per_class,\n",
    "    'Recall': recall_per_class,\n",
    "    'F1-Score': f1_per_class\n",
    "})\n",
    "\n",
    "# Trier par F1-Score\n",
    "per_class_df = per_class_df.sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š MÃ©triques par Ã©motion (Top 10):\")\n",
    "print(per_class_df.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nðŸ“Š MÃ©triques par Ã©motion (Bottom 5):\")\n",
    "print(per_class_df.tail(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017eac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des mÃ©triques par classe\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "x = np.arange(len(emotion_labels))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, precision_per_class, width, label='Precision', alpha=0.8)\n",
    "ax.bar(x, recall_per_class, width, label='Recall', alpha=0.8)\n",
    "ax.bar(x + width, f1_per_class, width, label='F1-Score', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Ã‰motion', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
    "ax.set_title('MÃ©triques par Ã‰motion - ModÃ¨le LSTM', fontweight='bold', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(emotion_labels, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/lstm_per_class_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939e4f9c",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ 7. Courbes ROC par Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b752a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š TracÃ© des courbes ROC pour les 10 meilleures classes (par AUC-ROC)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“ˆ GÃ‰NÃ‰RATION DES COURBES ROC\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# SÃ©lectionner les 10 classes avec les meilleurs AUC-ROC\n",
    "top_10_classes = per_class_df.head(10)['Emotion'].tolist()\n",
    "top_10_indices = [emotion_labels.index(em) for em in top_10_classes]\n",
    "\n",
    "# CrÃ©er le graphique\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Couleurs variÃ©es\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "\n",
    "for idx, (class_idx, color) in enumerate(zip(top_10_indices, colors)):\n",
    "    # Calculer la courbe ROC pour cette classe\n",
    "    fpr, tpr, _ = roc_curve(y_test[:, class_idx], y_pred_proba[:, class_idx])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Tracer la courbe\n",
    "    ax.plot(fpr, tpr, color=color, lw=2, \n",
    "            label=f'{emotion_labels[class_idx]} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "# Ligne diagonale (classificateur alÃ©atoire)\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Hasard (AUC = 0.500)')\n",
    "\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('Taux de Faux Positifs', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Taux de Vrais Positifs', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Courbes ROC - Top 10 Ã‰motions (LSTM)', fontweight='bold', fontsize=14)\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/lstm_roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Courbes ROC gÃ©nÃ©rÃ©es et sauvegardÃ©es: results/figures/lstm_roc_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3861fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ Calcul de l'AUC-ROC (requis par l'Ã©noncÃ©)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“ˆ CALCUL DE L'AUC-ROC\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# AUC-ROC Micro (moyenne globale sur toutes les classes)\n",
    "auc_micro = roc_auc_score(y_test, y_pred_proba, average='micro')\n",
    "print(f\"AUC-ROC (Micro): {auc_micro:.4f}\")\n",
    "\n",
    "# AUC-ROC Macro (moyenne non pondÃ©rÃ©e par classe)\n",
    "auc_macro = roc_auc_score(y_test, y_pred_proba, average='macro')\n",
    "print(f\"AUC-ROC (Macro): {auc_macro:.4f}\")\n",
    "\n",
    "# AUC-ROC par classe\n",
    "auc_per_class = roc_auc_score(y_test, y_pred_proba, average=None)\n",
    "per_class_df['AUC-ROC'] = auc_per_class\n",
    "per_class_df = per_class_df.sort_values('AUC-ROC', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š AUC-ROC par Ã©motion (Top 10):\")\n",
    "print(per_class_df[['Emotion', 'AUC-ROC']].head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nðŸ“Š AUC-ROC par Ã©motion (Bottom 5):\")\n",
    "print(per_class_df[['Emotion', 'AUC-ROC']].tail(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f28a666",
   "metadata": {},
   "source": [
    "## ðŸ’¾ 8. Sauvegarde des RÃ©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f14b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sauvegarde des rÃ©sultats...\\n\")\n",
    "\n",
    "# ðŸ’¾ Sauvegarder le modÃ¨le au format .pickle (requis par l'Ã©noncÃ©)\n",
    "print(\"ðŸ“¦ Sauvegarde du modÃ¨le au format .pickle...\")\n",
    "model_data = {\n",
    "    'model_config': lstm_model.get_config(),\n",
    "    'model_weights': lstm_model.get_weights(),\n",
    "    'vocab_size': vocab_size,\n",
    "    'max_length': max_length,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'emotion_labels': emotion_labels\n",
    "}\n",
    "with open('models/lstm/lstm_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "print(\"âœ… ModÃ¨le sauvegardÃ©: models/lstm/lstm_model.pickle\")\n",
    "\n",
    "# Sauvegarder aussi au format .h5 pour compatibilitÃ©\n",
    "lstm_model.save('models/lstm/final_model.h5')\n",
    "print(\"âœ… ModÃ¨le sauvegardÃ© (format .h5): models/lstm/final_model.h5\")\n",
    "\n",
    "# Sauvegarder l'historique d'entraÃ®nement\n",
    "with open('models/lstm/training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "print(\"âœ… Historique sauvegardÃ©: models/lstm/training_history.pkl\")\n",
    "\n",
    "# Mettre Ã  jour les rÃ©sultats avec AUC-ROC\n",
    "results['auc_roc_micro'] = float(auc_micro)\n",
    "results['auc_roc_macro'] = float(auc_macro)\n",
    "\n",
    "# Sauvegarder les rÃ©sultats au format JSON\n",
    "with open('results/metrics/lstm_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "print(\"âœ… RÃ©sultats sauvegardÃ©s: results/metrics/lstm_results.json\")\n",
    "\n",
    "# Sauvegarder les prÃ©dictions\n",
    "np.save('models/lstm/test_predictions.npy', y_pred)\n",
    "np.save('models/lstm/test_probabilities.npy', y_pred_proba)\n",
    "print(\"âœ… PrÃ©dictions sauvegardÃ©es\")\n",
    "\n",
    "# Sauvegarder les mÃ©triques par classe (avec AUC-ROC)\n",
    "per_class_df.to_csv('results/metrics/lstm_per_class_metrics.csv', index=False)\n",
    "print(\"âœ… MÃ©triques par classe sauvegardÃ©es: results/metrics/lstm_per_class_metrics.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ‰ LSTM - ENTRAÃŽNEMENT ET Ã‰VALUATION TERMINÃ‰S !\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nProcÃ©dez au notebook suivant:\")\n",
    "print(\"  ðŸ““ Personne_2_BiLSTM_Attention.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ff653",
   "metadata": {},
   "source": [
    "## ðŸ“¤ 9. [Optionnel] Sauvegarder vers Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monter Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copier les rÃ©sultats\n",
    "!mkdir -p \"/content/drive/MyDrive/emotion_detection_project\"\n",
    "!cp -r models/lstm \"/content/drive/MyDrive/emotion_detection_project/\"\n",
    "!cp -r results \"/content/drive/MyDrive/emotion_detection_project/\"\n",
    "\n",
    "print(\"\\nâœ… RÃ©sultats LSTM sauvegardÃ©s dans Google Drive!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
