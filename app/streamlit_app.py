"""
Interface Streamlit pour la D√©tection d'√âmotions
Projet GoEmotions - 28 √âmotions
"""

import streamlit as st
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import pickle
import plotly.graph_objects as go
import plotly.express as px
import re
import os

# Configuration de la page
st.set_page_config(
    page_title="D√©tection d'√âmotions - GoEmotions",
    page_icon="üòä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Liste des 28 √©motions
EMOTIONS = [
    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',
    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',
    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',
    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',
    'relief', 'remorse', 'sadness', 'surprise', 'neutral'
]

MAX_SEQUENCE_LENGTH = 128

# Fonction de nettoyage du texte
def clean_text(text):
    """Nettoie le texte comme dans le preprocessing"""
    text = text.lower()
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'\@\w+|\#', '', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# Chargement des mod√®les
@st.cache_resource
def load_tokenizer():
    """Charge le tokenizer"""
    try:
        # Essayer plusieurs chemins possibles
        paths = [
            '../models/lstm/tokenizer.pkl',
            'models/lstm/tokenizer.pkl',
            '../data/processed/tokenizer.pkl',
            'data/processed/tokenizer.pkl'
        ]
        for path in paths:
            if os.path.exists(path):
                with open(path, 'rb') as f:
                    return pickle.load(f)
        st.warning("‚ö†Ô∏è Tokenizer non trouv√©. Cr√©er un tokenizer de base.")
        return keras.preprocessing.text.Tokenizer(num_words=10000)
    except Exception as e:
        st.error(f"Erreur de chargement du tokenizer: {e}")
        return keras.preprocessing.text.Tokenizer(num_words=10000)

@st.cache_resource
def load_model(model_name):
    """Charge le mod√®le s√©lectionn√©"""
    model_paths = {
        'LSTM': '../models/lstm/model.h5',
        'BiLSTM + Attention': '../models/bilstm/model.h5',
        'CNN-BiLSTM + Attention': '../models/cnn_bilstm/model.h5',
        'BERT': '../models/bert/model.h5'
    }
    
    try:
        path = model_paths[model_name]
        if not os.path.exists(path):
            # Essayer sans ../
            path = path.replace('../', '')
        model = keras.models.load_model(path, compile=False)
        return model
    except Exception as e:
        st.error(f"‚ùå Erreur de chargement du mod√®le {model_name}: {e}")
        return None

# Fonction de pr√©diction
def predict_emotions(text, model, tokenizer, top_k=10):
    """Pr√©dit les √©motions pour un texte donn√©"""
    # Nettoyage
    cleaned_text = clean_text(text)
    
    # Tokenization
    sequences = tokenizer.texts_to_sequences([cleaned_text])
    padded = keras.preprocessing.sequence.pad_sequences(
        sequences, 
        maxlen=MAX_SEQUENCE_LENGTH, 
        padding='post'
    )
    
    # Pr√©diction
    predictions = model.predict(padded, verbose=0)[0]
    
    # Top K √©motions
    top_indices = np.argsort(predictions)[-top_k:][::-1]
    top_emotions = [EMOTIONS[i] for i in top_indices]
    top_probs = [predictions[i] for i in top_indices]
    
    return top_emotions, top_probs, predictions

# Interface principale
def main():
    # Titre et description
    st.title("üé≠ D√©tecteur d'√âmotions - GoEmotions Dataset")
    st.markdown("""
    Cette application utilise des mod√®les de Deep Learning pour d√©tecter **28 √©motions** 
    diff√©rentes dans un texte. Bas√©e sur le dataset **GoEmotions** (58,000 commentaires Reddit).
    """)
    
    # Sidebar - Configuration
    st.sidebar.title("‚öôÔ∏è Configuration")
    
    model_choice = st.sidebar.selectbox(
        "S√©lectionner un mod√®le",
        ["LSTM", "BiLSTM + Attention", "CNN-BiLSTM + Attention", "BERT"]
    )
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üìä Informations du Mod√®le")
    
    # Informations sur les mod√®les
    model_info = {
        "LSTM": {
            "description": "Mod√®le baseline avec LSTM simple",
            "params": "~500K param√®tres",
            "temps": "~15-20 min"
        },
        "BiLSTM + Attention": {
            "description": "BiLSTM avec m√©canisme d'attention",
            "params": "~800K param√®tres",
            "temps": "~30-40 min"
        },
        "CNN-BiLSTM + Attention": {
            "description": "Architecture hybride CNN + BiLSTM",
            "params": "~1M param√®tres",
            "temps": "~40-50 min"
        },
        "BERT": {
            "description": "Fine-tuning BERT-base-uncased",
            "params": "~110M param√®tres",
            "temps": "~50-60 min"
        }
    }
    
    st.sidebar.info(f"**{model_choice}**\n\n{model_info[model_choice]['description']}")
    st.sidebar.caption(f"‚ö° {model_info[model_choice]['params']}")
    
    # Chargement des ressources
    with st.spinner("Chargement du tokenizer..."):
        tokenizer = load_tokenizer()
    
    with st.spinner(f"Chargement du mod√®le {model_choice}..."):
        model = load_model(model_choice)
    
    if model is None:
        st.error("‚ùå Impossible de charger le mod√®le. V√©rifiez que les mod√®les sont entra√Æn√©s.")
        st.info("üí° **Instructions** : Ex√©cutez d'abord les notebooks d'entra√Ænement (Notebook_1 √† Notebook_4)")
        return
    
    st.success(f"‚úÖ Mod√®le {model_choice} charg√© avec succ√®s!")
    
    # Zone de saisie
    st.markdown("---")
    st.header("‚úçÔ∏è Entrez votre texte")
    
    # Exemples pr√©d√©finis
    examples = {
        "Exemple 1 (Joie)": "I'm so happy and excited about this amazing news!",
        "Exemple 2 (Col√®re)": "This is absolutely frustrating and makes me so angry!",
        "Exemple 3 (Tristesse)": "I feel so sad and disappointed about what happened.",
        "Exemple 4 (Surprise)": "Wow, I can't believe this happened! What a surprise!",
        "Exemple 5 (Peur)": "I'm really scared and nervous about the situation."
    }
    
    selected_example = st.selectbox("Ou choisir un exemple", ["---"] + list(examples.keys()))
    
    if selected_example != "---":
        default_text = examples[selected_example]
    else:
        default_text = ""
    
    user_input = st.text_area(
        "Texte √† analyser",
        value=default_text,
        height=150,
        placeholder="Entrez un texte en anglais (ex: I love this wonderful day!)",
        help="Le mod√®le fonctionne mieux avec du texte en anglais"
    )
    
    col1, col2, col3 = st.columns([1, 1, 4])
    with col1:
        analyze_button = st.button("üîç Analyser", type="primary")
    with col2:
        clear_button = st.button("üóëÔ∏è Effacer")
    
    if clear_button:
        st.rerun()
    
    # Analyse
    if analyze_button and user_input.strip():
        with st.spinner("Analyse en cours..."):
            top_emotions, top_probs, all_predictions = predict_emotions(
                user_input, model, tokenizer, top_k=10
            )
        
        # R√©sultats
        st.markdown("---")
        st.header("üìä R√©sultats de l'Analyse")
        
        # M√©triques principales
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric(
                "ü•á √âmotion Principale", 
                top_emotions[0].capitalize(),
                f"{top_probs[0]:.1%}"
            )
        with col2:
            st.metric(
                "ü•à Deuxi√®me √âmotion", 
                top_emotions[1].capitalize(),
                f"{top_probs[1]:.1%}"
            )
        with col3:
            st.metric(
                "ü•â Troisi√®me √âmotion", 
                top_emotions[2].capitalize(),
                f"{top_probs[2]:.1%}"
            )
        
        # Visualisations
        tab1, tab2, tab3 = st.tabs(["üìä Top 10 √âmotions", "üéØ Toutes les √âmotions", "üìà Distribution"])
        
        with tab1:
            # Graphique en barres - Top 10
            fig = go.Figure(data=[
                go.Bar(
                    x=top_probs,
                    y=[e.capitalize() for e in top_emotions],
                    orientation='h',
                    marker=dict(
                        color=top_probs,
                        colorscale='Viridis',
                        showscale=True,
                        colorbar=dict(title="Probabilit√©")
                    ),
                    text=[f"{p:.1%}" for p in top_probs],
                    textposition='auto',
                )
            ])
            
            fig.update_layout(
                title="Top 10 √âmotions D√©tect√©es",
                xaxis_title="Probabilit√©",
                yaxis_title="√âmotion",
                height=500,
                showlegend=False
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with tab2:
            # Toutes les √©motions
            emotions_df = pd.DataFrame({
                '√âmotion': EMOTIONS,
                'Probabilit√©': all_predictions
            }).sort_values('Probabilit√©', ascending=False)
            
            fig = px.bar(
                emotions_df,
                x='Probabilit√©',
                y='√âmotion',
                orientation='h',
                color='Probabilit√©',
                color_continuous_scale='RdYlGn',
                title="Distribution Compl√®te des 28 √âmotions"
            )
            
            fig.update_layout(height=800)
            st.plotly_chart(fig, use_container_width=True)
        
        with tab3:
            # Radar chart
            fig = go.Figure()
            
            fig.add_trace(go.Scatterpolar(
                r=top_probs[:8],
                theta=[e.capitalize() for e in top_emotions[:8]],
                fill='toself',
                name='√âmotions'
            ))
            
            fig.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, max(top_probs)]
                    )
                ),
                showlegend=False,
                title="Radar Chart - Top 8 √âmotions",
                height=500
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        # Tableau d√©taill√©
        st.markdown("---")
        st.subheader("üìã D√©tails des Pr√©dictions")
        
        results_df = pd.DataFrame({
            'Rang': range(1, 11),
            '√âmotion': [e.capitalize() for e in top_emotions],
            'Probabilit√©': [f"{p:.4f}" for p in top_probs],
            'Pourcentage': [f"{p:.2%}" for p in top_probs]
        })
        
        st.dataframe(results_df, use_container_width=True, hide_index=True)
        
        # Texte nettoy√©
        with st.expander("üßπ Voir le texte nettoy√©"):
            st.code(clean_text(user_input))
    
    elif analyze_button:
        st.warning("‚ö†Ô∏è Veuillez entrer un texte √† analyser.")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center'>
        <p>üéì Projet D√©tection d'√âmotions - Deep Learning</p>
        <p>üìö Dataset: GoEmotions (58,000 commentaires Reddit, 28 √©motions)</p>
        <p>üèõÔ∏è 3ING - Indexation et Recherche d'Information</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
