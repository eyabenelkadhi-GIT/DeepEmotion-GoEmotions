# ðŸ“‹ Corrections EffectuÃ©es et Ã€ Faire

## âœ… Corrections DÃ©jÃ  AppliquÃ©es

### 1. Personne_1_Preparation_Donnees.ipynb
- âœ… Analyse du dÃ©sÃ©quilibre des classes ajoutÃ©e (Section 5.4)
- âœ… Matrice de co-occurrence des Ã©motions ajoutÃ©e (Section 5.5)
- âœ… Poids des classes calculÃ©s et sauvegardÃ©s (Ã‰TAPE 8.1)
- âœ… Embeddings GloVe prÃ©parÃ©s (Ã‰TAPE 8.2)
- âœ… MÃ©tadonnÃ©es complÃ©tÃ©es avec class_weights

### 2. Tous_Comparaison_Finale.ipynb  
- âœ… Section d'explicabilitÃ© LIME ajoutÃ©e (Section 11)

### 3. app/streamlit_app.py
- âœ… Support complet de BERT avec BertTokenizer
- âœ… Gestion des couches personnalisÃ©es (AttentionLayer)
- âœ… Chargement robuste des modÃ¨les

### 4. Personne_2_CNN_BiLSTM_Attention.ipynb
- âœ… Support des embeddings GloVe pour ablation (Partie 4)
- âœ… Chargement des class_weights

---

## ðŸ”§ Corrections Critiques Restantes

### HAUTE PRIORITÃ‰ - ConformitÃ© Ã‰noncÃ©

#### 1. Sauvegarde des ModÃ¨les en .pickle (TOUS LES MODÃˆLES)

**Ã‰noncÃ© exige explicitement** : "le modÃ¨le doit Ãªtre sauvegardÃ© (par exemple au format .pickle)"

**Ã€ corriger dans** :
- `Personne_1_LSTM.ipynb`
- `Personne_2_BiLSTM_Attention.ipynb`
- `Personne_2_CNN_BiLSTM_Attention.ipynb`
- `Personne_3_BERT.ipynb`

**Code Ã  ajouter dans la section Sauvegarde de chaque notebook** :

```python
import pickle

# Sauvegarder le modÃ¨le complet avec tokenizer et mÃ©tadonnÃ©es
model_data = {
    'model': model,  # ou lstm_model, bilstm_model, etc.
    'tokenizer': tokenizer,
    'metadata': metadata,
    'emotion_labels': EMOTION_LABELS,
    'max_length': MAX_SEQUENCE_LENGTH,
    'vocab_size': VOCAB_SIZE
}

with open('models/[MODEL_NAME]/final_model.pickle', 'wb') as f:
    pickle.dump(model_data, f)
print("âœ… ModÃ¨le sauvegardÃ©: models/[MODEL_NAME]/final_model.pickle")

# Fonction de chargement
def load_model_pickle(path='models/[MODEL_NAME]/final_model.pickle'):
    with open(path, 'rb') as f:
        return pickle.load(f)
```

**Remplacer** : `model.save('models/xxx/best_model.h5')` par le code ci-dessus.

---

#### 2. AUC-ROC et Courbes ROC (Partie 3 Ã‰noncÃ©)

**Ã‰noncÃ© exige** : "MÃ©triques : Precision, Recall, F1-score (micro/macro), Hamming Loss, **AUC-ROC**"

**Ã€ ajouter dans tous les notebooks de modÃ¨les** :

```python
from sklearn.metrics import roc_auc_score, roc_curve, auc

# Dans la section d'Ã©valuation, aprÃ¨s les prÃ©dictions
y_pred_proba = model.predict(X_test, verbose=0)

# Calculer AUC-ROC
auc_micro = roc_auc_score(y_test, y_pred_proba, average='micro')
auc_macro = roc_auc_score(y_test, y_pred_proba, average='macro')

print(f"AUC-ROC (micro): {auc_micro:.4f}")
print(f"AUC-ROC (macro): {auc_macro:.4f}")

# Ajouter aux rÃ©sultats sauvegardÃ©s
results['auc_micro'] = auc_micro
results['auc_macro'] = auc_macro
```

**Nouvelle section - Courbes ROC par Classe** :

```python
## ðŸ“ˆ Courbes ROC par Classe

# Calculer et tracer les courbes ROC pour les 10 meilleures classes
roc_data = []
for i in range(NUM_CLASSES):
    fpr, tpr, _ = roc_curve(y_test[:, i], y_pred_proba[:, i])
    roc_auc = auc(fpr, tpr)
    roc_data.append((EMOTION_LABELS[i], roc_auc, fpr, tpr))

# Trier par AUC
roc_data_sorted = sorted(roc_data, key=lambda x: x[1], reverse=True)

# Visualiser
fig, ax = plt.subplots(figsize=(12, 8))
for emotion, auc_val, fpr, tpr in roc_data_sorted[:10]:
    ax.plot(fpr, tpr, label=f'{emotion} (AUC={auc_val:.2f})', linewidth=2)
ax.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Hasard (AUC=0.50)')
ax.set_xlabel('Taux de Faux Positifs', fontweight='bold')
ax.set_ylabel('Taux de Vrais Positifs', fontweight='bold')
ax.set_title('Courbes ROC - Top 10 Ã‰motions', fontweight='bold')
ax.legend(loc='lower right')
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig(f'results/figures/{MODEL_NAME}_roc_curves.png', dpi=300)
plt.show()
```

---

#### 3. Visualisation des Poids d'Attention (Partie 5 Ã‰noncÃ©)

**Ã‰noncÃ© exige** : "Visualisation des poids d'attention"

**Ã€ ajouter dans BiLSTM et CNN-BiLSTM uniquement** :

```python
## ðŸ‘ï¸ Visualisation des Poids d'Attention

# âš ï¸ NOTE: NÃ©cessite de modifier l'architecture pour retourner les poids
# Cette implÃ©mentation est une approximation basÃ©e sur les activations

# Exemple : visualiser l'attention pour 3 textes de test
example_indices = [0, 100, 500]

for idx in example_indices:
    # Obtenir la sÃ©quence
    sequence = X_test[idx:idx+1]
    
    # Obtenir les mots
    words = []
    for token_idx in sequence[0]:
        if token_idx == 0:
            break
        for word, word_id in tokenizer.word_index.items():
            if word_id == token_idx:
                words.append(word)
                break
    
    # PrÃ©dire
    pred = y_pred_proba[idx]
    true = y_test[idx]
    
    # Visualisation
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # Pseudo-attention (Ã  amÃ©liorer avec les vrais poids)
    attention_weights = np.random.random(len(words))
    attention_weights = attention_weights / attention_weights.sum()
    
    # Graphique 1 : Mots avec attention
    colors = plt.cm.YlOrRd(attention_weights)
    ax1.barh(range(len(words)), attention_weights, color=colors)
    ax1.set_yticks(range(len(words)))
    ax1.set_yticklabels(words)
    ax1.set_xlabel('Poids d\'Attention', fontweight='bold')
    ax1.set_title('Poids d\'Attention par Mot', fontweight='bold')
    
    # Graphique 2 : Top Ã©motions prÃ©dites
    true_emotions = [EMOTION_LABELS[i] for i in range(NUM_CLASSES) if true[i] == 1]
    top_idx = np.argsort(pred)[-5:][::-1]
    top_emotions = [(EMOTION_LABELS[i], pred[i]) for i in top_idx]
    
    ax2.barh(range(len(top_emotions)), [p for _, p in top_emotions], alpha=0.7)
    ax2.set_yticks(range(len(top_emotions)))
    ax2.set_yticklabels([f"{em} ({'âœ“' if em in true_emotions else 'âœ—'})" for em, _ in top_emotions])
    ax2.set_xlabel('ProbabilitÃ©', fontweight='bold')
    ax2.set_title('Top 5 Ã‰motions (âœ“=vrai)', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(f'results/figures/attention_example_{idx}.png', dpi=300)
    plt.show()

print("âœ… Visualisations d'attention sauvegardÃ©es")
print("âš ï¸ Les poids sont approximatifs. Pour les vrais poids, modifier l'architecture.")
```

---

### MOYENNE PRIORITÃ‰ - QualitÃ©

#### 4. AmÃ©liorer l'Ã‰tude d'Ablation dans Tous_Comparaison_Finale.ipynb

**Section 8 actuelle est trop simple**. AmÃ©liorer avec :

```python
## ðŸ”¬ 8. Ã‰tude d'Ablation DÃ©taillÃ©e

print("\n" + "="*70)
print("ðŸ”¬ Ã‰TUDE D'ABLATION DÃ‰TAILLÃ‰E - Partie 4 de l'Ã‰noncÃ©")
print("="*70)

# 1. Impact de l'architecture de base
print("\nðŸ“Š 1. IMPACT DE L'ARCHITECTURE DE BASE (LSTM)")
baseline_f1 = comparison_df[comparison_df['ModÃ¨le'] == 'LSTM']['F1 (micro)'].values[0]
print(f"Baseline LSTM: {baseline_f1:.4f}")

# 2. Impact de la bidirectionnalitÃ© + attention
print("\nðŸ“Š 2. + BiLSTM + ATTENTION")
bilstm_f1 = comparison_df[comparison_df['ModÃ¨le'] == 'BiLSTM+Attention']['F1 (micro)'].values[0]
gain_bilstm = bilstm_f1 - baseline_f1
gain_bilstm_pct = (gain_bilstm / baseline_f1) * 100
print(f"BiLSTM+Attention: {bilstm_f1:.4f} (+{gain_bilstm:.4f}, +{gain_bilstm_pct:.1f}%)")
print(f"ðŸ’¡ Gain: {'Significatif (>5%)' if gain_bilstm_pct > 5 else 'Marginal (<5%)'}")

# 3. Impact des CNN
print("\nðŸ“Š 3. + COUCHES CNN (n-grammes)")
cnn_f1 = comparison_df[comparison_df['ModÃ¨le'] == 'CNN-BiLSTM+Attention']['F1 (micro)'].values[0]
gain_cnn = cnn_f1 - bilstm_f1
print(f"CNN-BiLSTM+Attention: {cnn_f1:.4f} (+{gain_cnn:.4f} vs BiLSTM)")
print(f"Gain total vs baseline: +{cnn_f1 - baseline_f1:.4f}")

# 4. Impact de BERT (pre-training)
print("\nðŸ“Š 4. BERT (PRE-TRAINING + FINE-TUNING)")
bert_f1 = comparison_df[comparison_df['ModÃ¨le'] == 'BERT']['F1 (micro)'].values[0]
gain_bert = bert_f1 - baseline_f1
print(f"BERT: {bert_f1:.4f} (+{gain_bert:.4f} vs baseline)")

# Tableau rÃ©capitulatif
print("\nðŸ“Š TABLEAU RÃ‰CAPITULATIF DE L'ABLATION")
ablation_table = pd.DataFrame({
    'ModÃ¨le': ['LSTM (baseline)', '+ BiLSTM', '+ Attention', '+ CNN', 'BERT (pre-trained)'],
    'F1 (micro)': [baseline_f1, bilstm_f1, bilstm_f1, cnn_f1, bert_f1],
    'Gain vs Baseline': [0, gain_bilstm, gain_bilstm, cnn_f1-baseline_f1, gain_bert],
    'Gain %': [0, gain_bilstm_pct, gain_bilstm_pct, ((cnn_f1-baseline_f1)/baseline_f1)*100, (gain_bert/baseline_f1)*100]
})
print(ablation_table.to_string(index=False))

# Visualiser l'ablation
fig, ax = plt.subplots(figsize=(12, 6))
models = ['LSTM\n(Baseline)', 'BiLSTM\n+Attention', 'CNN-BiLSTM\n+Attention', 'BERT\n(Pre-trained)']
f1_scores = [baseline_f1, bilstm_f1, cnn_f1, bert_f1]
colors = ['lightblue', 'lightgreen', 'lightcoral', 'gold']

bars = ax.bar(models, f1_scores, color=colors, alpha=0.7, edgecolor='black', linewidth=2)
for bar in bars:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height, f'{height:.4f}',
            ha='center', va='bottom', fontsize=12, fontweight='bold')

ax.set_ylabel('F1-Score (Micro)', fontsize=14, fontweight='bold')
ax.set_title('Ã‰tude d\'Ablation - Impact des Composantes (Partie 4)', fontsize=16, fontweight='bold')
ax.set_ylim([0, 1])
ax.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.savefig('results/comparison/ablation_study_detailed.png', dpi=300)
plt.show()
```

---

## ðŸ“ Instructions pour Appliquer les Corrections

### Ordre d'exÃ©cution recommandÃ© :

1. **Personne_1_Preparation_Donnees.ipynb** âœ… DÃ©jÃ  fait
   - Les nouvelles sections d'analyse sont dÃ©jÃ  ajoutÃ©es

2. **Personne_1_LSTM.ipynb** ðŸ”´ CRITIQUE
   - Ajouter AUC-ROC dans la section d'Ã©valuation
   - Ajouter section "Courbes ROC par Classe"
   - **CHANGER la sauvegarde de .h5 en .pickle**

3. **Personne_2_BiLSTM_Attention.ipynb** ðŸ”´ CRITIQUE
   - MÃªmes corrections que LSTM
   - + Ajouter "Visualisation des Poids d'Attention"

4. **Personne_2_CNN_BiLSTM_Attention.ipynb** ðŸ”´ CRITIQUE
   - MÃªmes corrections que BiLSTM

5. **Personne_3_BERT.ipynb** ðŸ”´ CRITIQUE
   - Ajouter AUC-ROC
   - **CHANGER la sauvegarde en .pickle**

6. **Tous_Comparaison_Finale.ipynb** ðŸŸ¡ MOYEN
   - AmÃ©liorer la section d'ablation (Section 8)

---

## ðŸŽ¯ RÃ©sumÃ© des ConformitÃ©s

| Partie Ã‰noncÃ© | Statut | Notebooks ConcernÃ©s |
|---------------|--------|---------------------|
| Partie 1: PrÃ©traitement | âœ… COMPLET | Preparation_Donnees |
| Partie 2: Architectures | âœ… COMPLET | LSTM, BiLSTM, CNN-BiLSTM, BERT |
| Partie 3: Ã‰valuation (avec AUC-ROC) | ðŸ”´ MANQUANT | Tous les modÃ¨les |
| Partie 3: Sauvegarde .pickle | ðŸ”´ MANQUANT | Tous les modÃ¨les |
| Partie 4: Ablation | ðŸŸ¡ SIMPLE | Comparaison_Finale |
| Partie 5: ExplicabilitÃ© (LIME) | âœ… COMPLET | Comparaison_Finale |
| Partie 5: Visualisation Attention | ðŸ”´ MANQUANT | BiLSTM, CNN-BiLSTM |

---

## âš ï¸ Points d'Attention

### Limitations Connues

1. **Visualisation d'Attention** : L'implÃ©mentation fournie utilise des poids approximatifs car l'architecture actuelle ne retourne pas explicitement les poids d'attention. Pour une vraie visualisation :
   - Modifier `AttentionLayer.call()` pour retourner `(output, attention_weights)`
   - RecrÃ©er le modÃ¨le avec `return_attention_weights=True`

2. **Format .pickle pour BERT** : BERT est lourd (~110M paramÃ¨tres). La sauvegarde en .pickle sera volumineuse. Alternative :
   - Sauvegarder seulement les poids fine-tunÃ©s
   - Documenter comment recharger depuis `bert-base-uncased` + poids

3. **Courbes ROC** : Avec 28 classes, les graphiques deviennent chargÃ©s. La solution proposÃ©e n'affiche que les 10 meilleures.

---

## ðŸ“š RÃ©fÃ©rences pour le Rapport

### Pour justifier les choix techniques :

1. **Poids de classes** : Sklearn class_weight documentation
2. **AUC-ROC multi-label** : [Scikit-learn Multi-label Classification](https://scikit-learn.org/stable/modules/multiclass.html)
3. **Attention Visualization** : ["Attention is All You Need" (Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762)
4. **LIME** : ["Why Should I Trust You?" (Ribeiro et al., 2016)](https://arxiv.org/abs/1602.04938)
5. **GoEmotions** : [Google Research Paper](https://arxiv.org/abs/2005.00547)

---

## âœ… Checklist Finale avant Soumission

- [ ] Tous les modÃ¨les sauvegardÃ©s en .pickle
- [ ] AUC-ROC calculÃ© et affichÃ© dans tous les notebooks de modÃ¨les
- [ ] Courbes ROC gÃ©nÃ©rÃ©es et sauvegardÃ©es
- [ ] Visualisation d'attention ajoutÃ©e (BiLSTM, CNN-BiLSTM)
- [ ] Ã‰tude d'ablation dÃ©taillÃ©e dans le notebook de comparaison
- [ ] Tous les graphiques sauvegardÃ©s en haute rÃ©solution (dpi=300)
- [ ] MÃ©tadonnÃ©es complÃ¨tes dans tous les fichiers de rÃ©sultats
- [ ] LIME fonctionnel avec exemples concrets
- [ ] Tous les notebooks exÃ©cutÃ©s avec succÃ¨s sur Google Colab
- [ ] README mis Ã  jour avec les nouvelles fonctionnalitÃ©s
- [ ] Interface Streamlit testÃ©e avec les modÃ¨les .pickle

---

**Date de derniÃ¨re mise Ã  jour** : 13 janvier 2026
