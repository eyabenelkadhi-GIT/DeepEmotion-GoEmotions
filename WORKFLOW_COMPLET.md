# ğŸ”„ Workflow : Des Notebooks Ã  l'Interface Streamlit

## ğŸ“‹ Vue d'ensemble

```
Ã‰TAPE 1: PrÃ©paration       â†’ Notebook_0 (Personne 1)
Ã‰TAPE 2: EntraÃ®nement      â†’ Notebooks 1-4 (3 personnes en parallÃ¨le)
Ã‰TAPE 3: Comparaison       â†’ Notebook_5 (Tous ensemble)
Ã‰TAPE 4: Interface         â†’ Streamlit (Sur PC local)
```

---

## ğŸ¯ Ã‰TAPE 1 : PrÃ©paration des DonnÃ©es (Personne 1)

### Qui fait quoi ?
**UN SEUL MEMBRE** (Personne 1) exÃ©cute **Personne_1_Preparation_Donnees.ipynb**

### Pourquoi ?
- âœ… Gagner du temps (pas besoin de tÃ©lÃ©charger 3 fois le dataset)
- âœ… Assurer la cohÃ©rence (mÃªme tokenizer pour tous)
- âœ… Ã‰viter les duplications

### Actions de Personne 1 :
1. Ouvrir **Personne_1_Preparation_Donnees.ipynb** sur Google Colab
2. **TÃ©lÃ©charger dataset depuis Kaggle** :
   - Aller sur https://www.kaggle.com/datasets/debarshichanda/goemotions/data
   - Cliquer sur "Download" â†’ tÃ©lÃ©charger `goemotions.csv`
   - Uploader dans Colab (via le bouton upload dans la premiÃ¨re cellule)
3. ExÃ©cuter toutes les cellules
4. TÃ©lÃ©charger les fichiers gÃ©nÃ©rÃ©s :
   ```python
   # Dans la derniÃ¨re cellule de Notebook_0
   from google.colab import files
   !zip -r data_processed.zip /content/data/processed/
   files.download('data_processed.zip')
   ```
5. Partager `data_processed.zip` sur Google Drive avec l'Ã©quipe

### Actions de Personne 2 et 3 :
1. TÃ©lÃ©charger `data_processed.zip` depuis Drive
2. Dans chaque notebook (1-4), ajouter cette cellule au dÃ©but :
   ```python
   # Uploader le fichier data_processed.zip
   from google.colab import files
   uploaded = files.upload()  # SÃ©lectionner data_processed.zip
   
   # Extraire
   !unzip -q data_processed.zip -d /content/
   
   # VÃ©rifier
   !ls /content/data/processed/
   ```

---

## ğŸš€ Ã‰TAPE 2 : EntraÃ®nement des ModÃ¨les

### Chaque membre exÃ©cute ses notebooks

**Personne 1 :**
- Personne_1_LSTM.ipynb

**Personne 2 :**
- Personne_2_BiLSTM_Attention.ipynb
- Personne_2_CNN_BiLSTM_Attention.ipynb

**Personne 3 :**
- Personne_3_BERT.ipynb (avec GPU)

### Important : Sauvegarder les modÃ¨les
Chaque notebook sauvegarde automatiquement dans `/content/models/{nom_modele}/` :
- `model.h5` : Le modÃ¨le entraÃ®nÃ©
- `results.json` : MÃ©triques (F1, precision, recall, etc.)
- `predictions.npy` : PrÃ©dictions sur test set

### TÃ©lÃ©charger les modÃ¨les aprÃ¨s entraÃ®nement
Ã€ la fin de chaque notebook, ajouter :
```python
# TÃ©lÃ©charger le modÃ¨le entraÃ®nÃ©
from google.colab import files

# Pour LSTM (Personne 1)
!zip -r lstm_model.zip /content/models/lstm/
files.download('lstm_model.zip')

# Pour BiLSTM (Personne 2)
!zip -r bilstm_model.zip /content/models/bilstm/
files.download('bilstm_model.zip')

# Pour CNN-BiLSTM (Personne 2)
!zip -r cnn_bilstm_model.zip /content/models/cnn_bilstm/
files.download('cnn_bilstm_model.zip')

# Pour BERT (Personne 3)
!zip -r bert_model.zip /content/models/bert/
files.download('bert_model.zip')
```

---

## ğŸ“Š Ã‰TAPE 3 : Comparaison Finale (Tous ensemble)

### PrÃ©paration
1. Chaque membre partage son fichier .zip sur Drive
2. Un membre rassemble tous les modÃ¨les dans un dossier Drive commun

### Dans Tous_Comparaison_Finale.ipynb
1. Uploader tous les fichiers .zip des modÃ¨les
2. Extraire :
   ```python
   !unzip -q lstm_model.zip -d /content/
   !unzip -q bilstm_model.zip -d /content/
   !unzip -q cnn_bilstm_model.zip -d /content/
   !unzip -q bert_model.zip -d /content/
   ```
3. ExÃ©cuter Notebook_5 pour la comparaison

---

## ğŸ¨ Ã‰TAPE 4 : Interface Streamlit (Sur PC Local)

### PrÃ©paration de l'environnement

1. **CrÃ©er la structure locale**
   ```
   projet/
   â”œâ”€â”€ app/
   â”‚   â””â”€â”€ streamlit_app.py    (dÃ©jÃ  crÃ©Ã© âœ…)
   â”œâ”€â”€ models/
   â”‚   â”œâ”€â”€ lstm/
   â”‚   â”‚   â”œâ”€â”€ model.h5
   â”‚   â”‚   â””â”€â”€ tokenizer.pkl
   â”‚   â”œâ”€â”€ bilstm/
   â”‚   â”‚   â””â”€â”€ model.h5
   â”‚   â”œâ”€â”€ cnn_bilstm/
   â”‚   â”‚   â””â”€â”€ model.h5
   â”‚   â””â”€â”€ bert/
   â”‚       â””â”€â”€ model.h5
   â””â”€â”€ data/
       â””â”€â”€ processed/
           â””â”€â”€ tokenizer.pkl
   ```

2. **TÃ©lÃ©charger et extraire tous les modÃ¨les**
   - TÃ©lÃ©charger les 4 fichiers .zip depuis Colab
   - Extraire dans le dossier `projet/models/`

3. **Copier le tokenizer**
   ```bash
   # Le tokenizer est dans data_processed.zip
   # Copier tokenizer.pkl dans models/lstm/ et data/processed/
   ```

### Lancement de l'interface

1. **Installation des dÃ©pendances**
   ```bash
   cd projet/
   pip install -r requirements.txt
   ```

2. **VÃ©rifier que les modÃ¨les sont prÃ©sents**
   ```bash
   # Windows PowerShell
   Get-ChildItem models -Recurse -Filter *.h5
   
   # Devrait afficher :
   # models/lstm/model.h5
   # models/bilstm/model.h5
   # models/cnn_bilstm/model.h5
   # models/bert/model.h5
   ```

3. **Lancer Streamlit**
   ```bash
   cd projet/
   streamlit run app/streamlit_app.py
   ```

4. **AccÃ©der Ã  l'interface**
   - Ouvrir automatiquement : http://localhost:8501
   - Ou manuellement dans le navigateur

### Utilisation de l'interface

1. **SÃ©lectionner un modÃ¨le** (sidebar gauche)
   - LSTM
   - BiLSTM + Attention
   - CNN-BiLSTM + Attention
   - BERT

2. **Entrer un texte ou choisir un exemple**
   - Ex: "I'm so happy and excited about this amazing news!"

3. **Cliquer sur "Analyser"**
   - L'interface charge le modÃ¨le
   - PrÃ©dit les Ã©motions
   - Affiche les rÃ©sultats

4. **Explorer les visualisations**
   - Top 10 Ã©motions (barres horizontales)
   - Distribution complÃ¨te (28 Ã©motions)
   - Radar chart

5. **Prendre des captures d'Ã©cran** pour le rapport

---

## ğŸ“¸ Captures d'Ã‰cran pour le Rapport

### Ã€ capturer :
1. **Page principale** avec sÃ©lection de modÃ¨le
2. **Exemple de prÃ©diction** (texte joyeux â†’ Ã©motion "joy")
3. **Top 10 Ã©motions** (graphique en barres)
4. **Radar chart**
5. **Distribution des 28 Ã©motions**
6. **Comparaison** entre 2 modÃ¨les (mÃªme texte, modÃ¨les diffÃ©rents)

---

## ğŸ”§ DÃ©pannage

### ProblÃ¨me : ModÃ¨le introuvable
```
âŒ Erreur : Impossible de charger le modÃ¨le LSTM
```
**Solution :**
- VÃ©rifier que `models/lstm/model.h5` existe
- VÃ©rifier le chemin dans `streamlit_app.py` (ligne 76-81)

### ProblÃ¨me : Tokenizer introuvable
```
âš ï¸ Tokenizer non trouvÃ©. CrÃ©er un tokenizer de base.
```
**Solution :**
- Copier `tokenizer.pkl` depuis `data_processed.zip`
- Placer dans `models/lstm/tokenizer.pkl` OU `data/processed/tokenizer.pkl`

### ProblÃ¨me : Importation TensorFlow
```
ModuleNotFoundError: No module named 'tensorflow'
```
**Solution :**
```bash
pip install tensorflow==2.15.0
```

### ProblÃ¨me : Importation Plotly
```
ModuleNotFoundError: No module named 'plotly'
```
**Solution :**
```bash
pip install plotly streamlit
```

---

## âœ… Checklist ComplÃ¨te

### Phase 1 : DonnÃ©es
- [ ] Personne 1 exÃ©cute Notebook_0
- [ ] Personne 1 tÃ©lÃ©charge data_processed.zip
- [ ] Personne 1 partage sur Drive
- [ ] Personnes 2 et 3 tÃ©lÃ©chargent data_processed.zip

### Phase 2 : EntraÃ®nement
- [ ] Personne 1 entraÃ®ne LSTM â†’ tÃ©lÃ©charge lstm_model.zip
- [ ] Personne 2 entraÃ®ne BiLSTM â†’ tÃ©lÃ©charge bilstm_model.zip
- [ ] Personne 2 entraÃ®ne CNN-BiLSTM â†’ tÃ©lÃ©charge cnn_bilstm_model.zip
- [ ] Personne 3 entraÃ®ne BERT â†’ tÃ©lÃ©charge bert_model.zip
- [ ] Tous partagent leurs .zip sur Drive

### Phase 3 : Comparaison
- [ ] Rassembler tous les modÃ¨les
- [ ] ExÃ©cuter Notebook_5
- [ ] Analyser les rÃ©sultats

### Phase 4 : Interface
- [ ] Extraire tous les .zip dans projet/models/
- [ ] Copier tokenizer.pkl dans les bons dossiers
- [ ] Installer dÃ©pendances : `pip install -r requirements.txt`
- [ ] Lancer : `streamlit run app/streamlit_app.py`
- [ ] Tester avec les 4 modÃ¨les
- [ ] Prendre 6+ captures d'Ã©cran
- [ ] Inclure dans le rapport

---

## ğŸ¯ RÃ©sumÃ©

| Ã‰tape | Qui | OÃ¹ | DurÃ©e |
|-------|-----|-----|-------|
| 1. DonnÃ©es | Personne 1 | Colab | 15-20 min |
| 2. LSTM | Personne 1 | Colab | 15-20 min |
| 2. BiLSTM + CNN | Personne 2 | Colab | 1h10 |
| 2. BERT | Personne 3 | Colab | 1h |
| 3. Comparaison | Tous | Colab | 15 min |
| 4. Interface | Tous | PC local | 30 min setup + dÃ©mo |

**Temps total : ~3h sur Colab + 30 min interface**

---

## ğŸ’¡ Conseils

1. **Communication** : CrÃ©er un groupe WhatsApp/Discord pour coordination
2. **Partage** : Utiliser Google Drive partagÃ© dÃ¨s le dÃ©but
3. **Sauvegarde** : TÃ©lÃ©charger TOUJOURS les modÃ¨les aprÃ¨s entraÃ®nement
4. **Test** : Tester l'interface AVANT la prÃ©sentation finale
5. **Backup** : Garder une copie de tous les .zip sur Drive
